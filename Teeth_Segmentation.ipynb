{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rH6Z4tJJYi33"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVl_uwBmSNVM"
      },
      "source": [
        "### Downloading the Teeth Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSh0F6mKYi33"
      },
      "source": [
        "First the dataset need to be downloaded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-03T12:54:42.172022Z",
          "iopub.status.busy": "2024-10-03T12:54:42.171594Z",
          "iopub.status.idle": "2024-10-03T12:54:42.176491Z",
          "shell.execute_reply": "2024-10-03T12:54:42.175412Z",
          "shell.execute_reply.started": "2024-10-03T12:54:42.171973Z"
        },
        "id": "gCW90FvnYi34",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\raksh\\anaconda3\\envs\\unet_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets tqdm -q\n",
        "from huggingface_hub import login\n",
        "from datasets import load_dataset\n",
        "from huggingface_hub import snapshot_download\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fXkqU5wG6iaw"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fetching 2 files: 100%|██████████| 2/2 [00:06<00:00,  3.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset downloaded completely.\n",
            "Total size of downloaded files: 86.07 MB\n",
            "Dataset has been saved at: [c:\\Users\\raksh\\Teeth-Segmentation-using-Unet\\Main_teeth_dataset]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "dataset_id=\"RayanAi/Main_teeth_dataset\"\n",
        "# Set the local directory where you want to store the dataset\n",
        "local_dataset_dir = \"./Main_teeth_dataset\"  # You can change this path to your desired location\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(local_dataset_dir, exist_ok=True)\n",
        "\n",
        "# Suppress the output by redirecting it to os.devnull\n",
        "with open(os.devnull, 'w') as fnull:\n",
        "    # Save the original stdout\n",
        "    original_stdout = sys.stdout\n",
        "    try:\n",
        "        # Redirect stdout to devnull to suppress output\n",
        "        sys.stdout = fnull\n",
        "        # Download the dataset and store it locally\n",
        "        snapshot_download(repo_id=dataset_id, local_dir=local_dataset_dir, repo_type=\"dataset\")\n",
        "    finally:\n",
        "        # Restore the original stdout\n",
        "        sys.stdout = original_stdout\n",
        "\n",
        "# Print message when download is complete\n",
        "print(\"Dataset downloaded completely.\")\n",
        "\n",
        "# Calculate and print the total size of the downloaded files\n",
        "total_size = 0\n",
        "for dirpath, dirnames, filenames in os.walk(local_dataset_dir):\n",
        "    for f in filenames:\n",
        "        fp = os.path.join(dirpath, f)\n",
        "        total_size += os.path.getsize(fp)\n",
        "\n",
        "# Convert size to MB and print\n",
        "print(f\"Total size of downloaded files: {total_size / (1024 * 1024):.2f} MB\")\n",
        "\n",
        "# Get the absolute path of the dataset directory and print it\n",
        "dataset_abs_path = os.path.abspath(local_dataset_dir)\n",
        "print(f\"Dataset has been saved at: [{dataset_abs_path}]\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SFB6bWJt8pfJ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'unzip' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!unzip -q ./Main_teeth_dataset/Main_teeth_dataset.zip -d ./Main_teeth_dataset/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6Hse5G8hOQ9"
      },
      "source": [
        "### Handling Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7BAty5ZLdE3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "#Define the split ratio\n",
        "split_ratio = 0.8\n",
        "\n",
        "#Write a Dataset function called TeethSegmentationDataset\n",
        "\n",
        "\n",
        "#Write a Dataset function called TeethSegmentationDataset\n",
        "class TeethSegmentationDataset(Dataset):\n",
        "    def __init__(self, image_dir: str, mask_dir: str, transform: A.Compose, dataset_type: str = 'Train', noisy_masks: list = None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            image_dir (str): Directory path containing input images.\n",
        "            mask_dir (str): Directory path containing corresponding segmentation masks.\n",
        "            transform (callable): Optional transformation to be applied to both the image and the mask. Use A.Compose. Use ToTensorV2()\n",
        "            dataset_type (str, optional): Type of dataset, e.g., 'Train' or 'Test'. Defaults to 'Train'.\n",
        "            noisy_masks (list, optional): Provide a list of names for images you want to be excluded from dataset\n",
        "        \"\"\"\n",
        "        # Initialize paths and transformation\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.transform = transform\n",
        "        self.dataset_type = dataset_type\n",
        "\n",
        "        # List of all images and masks\n",
        "        self.images = os.listdir(image_dir)\n",
        "        self.masks = os.listdir(mask_dir)\n",
        "        # Filter out noisy masks if provided\n",
        "        if noisy_masks:\n",
        "            self.images = [img for img in self.images if img not in noisy_masks]\n",
        "            self.masks = [mask for mask in self.masks if mask not in noisy_masks]\n",
        "        number_of_samples = len(self.images)\n",
        "\n",
        "        if dataset_type == 'Train':\n",
        "            self.images = self.images[:int(number_of_samples*split_ratio)]\n",
        "            self.masks = self.masks[:int(number_of_samples*split_ratio)]\n",
        "        elif dataset_type == 'Test':\n",
        "            self.images = os.listdir(image_dir)[int(number_of_samples*split_ratio):]\n",
        "            self.masks = os.listdir(mask_dir)[int(number_of_samples*split_ratio):]\n",
        "\n",
        "\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"\n",
        "        Returns:\n",
        "            int: The total number of image-mask pairs in the designated dataset split.\n",
        "        \"\"\"\n",
        "        # Return the length of the dataset (number of images)\n",
        "        return len(self.images)\n",
        "\n",
        "\n",
        "    def __getitem__(self, index: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            index (int): Index of the image-mask pair to retrieve.\n",
        "\n",
        "        Returns:\n",
        "            Tuple[torch.Tensor, torch.Tensor]: A tuple containing the image and its corresponding one-hot encoded mask.\n",
        "                - image (torch.Tensor): Transformed image tensor.\n",
        "                - onehot_mask (torch.Tensor): One-hot encoded mask tensor for segmentation.\n",
        "        \"\"\"\n",
        "        # Load the image and mask\n",
        "        image_path = os.path.join(self.image_dir, self.images[index])\n",
        "        mask_path = os.path.join(self.mask_dir, self.masks[index])\n",
        "\n",
        "        # Load image and mask as grayscale\n",
        "        image = np.array(Image.open(image_path).convert(\"L\"))\n",
        "        mask = np.array(Image.open(mask_path).convert(\"L\"))\n",
        "        transformed = self.transform(image=image, mask=mask)\n",
        "        image = transformed['image']\n",
        "        mask = transformed['mask']\n",
        "        binary_mask = mask.unsqueeze(2)>0\n",
        "        binary_mask = binary_mask.permute(2, 0, 1).float()\n",
        "\n",
        "        return image, binary_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-10-03T12:55:46.601863Z",
          "iopub.status.busy": "2024-10-03T12:55:46.601464Z",
          "iopub.status.idle": "2024-10-03T12:55:50.907443Z",
          "shell.execute_reply": "2024-10-03T12:55:50.906555Z",
          "shell.execute_reply.started": "2024-10-03T12:55:46.601819Z"
        },
        "id": "YjQTJPp_Yi35",
        "outputId": "e7672494-cbd0-447b-89e8-97689e45d4b8",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.18 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n"
          ]
        }
      ],
      "source": [
        "######################augmenters######################\n",
        "#You may want to alter this part\n",
        "augmenter = A.Compose([\n",
        "    A.Normalize(mean=(0.485,), std=(0.229,), max_pixel_value=255.0),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "######################################################\n",
        "\n",
        "######################################################\n",
        "#Don't touch this part\n",
        "test_augmenter = A.Compose([\n",
        "    A.Normalize(mean=(0.485,), std=(0.229,), max_pixel_value=255.0),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "######################################################\n",
        "\n",
        "train_dataset = TeethSegmentationDataset(\n",
        "    image_dir=\"./Main_teeth_dataset/images\",\n",
        "    mask_dir=\"./Main_teeth_dataset/labels\",\n",
        "    transform=augmenter,\n",
        "    dataset_type='Train',\n",
        "\n",
        ")\n",
        "\n",
        "test_dataset = TeethSegmentationDataset(\n",
        "    image_dir= \"./Main_teeth_dataset/images\",\n",
        "    mask_dir=\"./Main_teeth_dataset/labels\",\n",
        "    transform=test_augmenter,\n",
        "    dataset_type='Test',\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-03T12:55:50.909181Z",
          "iopub.status.busy": "2024-10-03T12:55:50.908756Z",
          "iopub.status.idle": "2024-10-03T12:55:50.914666Z",
          "shell.execute_reply": "2024-10-03T12:55:50.913661Z",
          "shell.execute_reply.started": "2024-10-03T12:55:50.909147Z"
        },
        "id": "BIDBT-kWYi35",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "batch_size=8\n",
        "num_workers=0 # Increase this if you have a powerfull cpu\n",
        "dataloaders = {\n",
        "  'train': DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers),\n",
        "  'test': DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "}\n",
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "print(f\"Test dataset size: {len(test_dataset)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UssW6iJ7Yi36"
      },
      "source": [
        "# Segmentation model\n",
        "In this part you should design a segmentation model. If you have defined any functions used to define your model, you should upload it along the model code.\n",
        "\n",
        "Your model shouldn't take any inputs or produce outputs when instantiating."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-uA9CsrYi36"
      },
      "source": [
        "<font color='red'>Important: You can only use functions availble in `torch` and `torchvision`.</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-03T12:55:52.845729Z",
          "iopub.status.busy": "2024-10-03T12:55:52.845422Z",
          "iopub.status.idle": "2024-10-03T12:55:52.866619Z",
          "shell.execute_reply": "2024-10-03T12:55:52.865746Z",
          "shell.execute_reply.started": "2024-10-03T12:55:52.845670Z"
        },
        "id": "kaXDqMPr8b1b",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Add your code here\n",
        "\n",
        "\n",
        "    #######DO NOT CHANGE THIS PART########\n",
        "    def init(self):\n",
        "        self.load_state_dict(torch.load('model.pth',weights_only=True))\n",
        "    ######################################\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        This method defines the forward pass of the model.\n",
        "\n",
        "        Args:\n",
        "            x (tensor): The input tensor, in the shape of (batch_size,1,512,512).\n",
        "\n",
        "        Returns:\n",
        "            mask (tensor): The output tensor logits, in the shape of (batch_size,1,512,512).\n",
        "        \"\"\"\n",
        "        # Add you code here\n",
        "        return mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-MwrpM_DlqD"
      },
      "outputs": [],
      "source": [
        "model = Model().to(device)\n",
        "\n",
        "image = next(iter(dataloaders['train']))[0].to(device)\n",
        "out = model(image)\n",
        "print(image.shape)\n",
        "print(out.shape)\n",
        "assert image.shape == (batch_size, 1, 512, 512), \"You shouldn't change the size of the image\"\n",
        "assert out.shape == (batch_size, 1, 512, 512), \"The output of your model do not have correct dimensions\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4Hn1LRJYi38"
      },
      "source": [
        "## Dice Score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmjpzwarYi38"
      },
      "source": [
        "Here is the dice score function. You model is evaluated based on the score from this function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-03T12:55:58.421930Z",
          "iopub.status.busy": "2024-10-03T12:55:58.421325Z",
          "iopub.status.idle": "2024-10-03T12:55:58.428953Z",
          "shell.execute_reply": "2024-10-03T12:55:58.427975Z",
          "shell.execute_reply.started": "2024-10-03T12:55:58.421887Z"
        },
        "id": "vG_qOEmpYi38",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def dice_score(pred: torch.Tensor, target_mask: torch.Tensor, epsilon: float = 1e-6) -> float:\n",
        "    \"\"\"\n",
        "    Computes the Dice score between the predicted and target segmentation masks.\n",
        "\n",
        "    Args:\n",
        "        pred (torch.Tensor): The predicted mask tensor, with values in range [0, 1].\n",
        "        target_one_target_maskhot (torch.Tensor): The ground truth mask.\n",
        "        epsilon (float, optional): A small value to avoid division by zero. Defaults to 1e-6.\n",
        "\n",
        "    Returns:\n",
        "        float: The Dice score, a similarity metric between 0 and 1.\n",
        "    \"\"\"\n",
        "    pred = pred>0\n",
        "    pred_flat = pred.contiguous().view(pred.shape[0], pred.shape[1], -1)\n",
        "    target_flat = target_mask.contiguous().view(target_mask.shape[0], target_mask.shape[1], -1)\n",
        "\n",
        "    intersection = (pred_flat * target_flat).sum(dim=-1)\n",
        "    union = pred_flat.sum(dim=-1) + target_flat.sum(dim=-1)\n",
        "\n",
        "    dice = (2. * intersection + epsilon) / (union + epsilon)\n",
        "\n",
        "    dice_mean = dice.mean(dim=1)\n",
        "\n",
        "    return dice_mean.mean()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnvf2rZZYi39"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-03T12:55:52.867995Z",
          "iopub.status.busy": "2024-10-03T12:55:52.867740Z",
          "iopub.status.idle": "2024-10-03T12:55:58.419880Z",
          "shell.execute_reply": "2024-10-03T12:55:58.419005Z",
          "shell.execute_reply.started": "2024-10-03T12:55:52.867967Z"
        },
        "id": "nVGqqpruBtJE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Define your optimizer and loss function\n",
        "#You can either use predefined loss functions or define one your self\n",
        "\n",
        "criterion =\n",
        "optimizer =\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSujS8GU5O8j"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def visualize_mask(inputs: torch.Tensor, masks: torch.Tensor, outputs: torch.Tensor):\n",
        "    # Convert tensors to numpy for visualization\n",
        "    sample_index = 0  # Index of the sample to visualize\n",
        "    channel = 0\n",
        "    print(f'Dice score is {dice_score(outputs[sample_index:sample_index+1,channel:channel+1],masks[sample_index:sample_index+1,channel:channel+1])}')\n",
        "\n",
        "    inputs_np = inputs.cpu().numpy()\n",
        "    masks_np = masks.cpu().numpy()\n",
        "    outputs_np = outputs.detach().cpu().numpy()\n",
        "\n",
        "    # Choose a sample to visualize\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(inputs_np[sample_index].transpose(1, 2, 0), cmap='gray')  # Assuming inputs are in CxHxW format\n",
        "    plt.title(\"Input Image\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(masks_np[sample_index, channel], cmap='gray')  # Display the first channel of the mask\n",
        "    plt.title(\"Ground Truth Mask\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(outputs_np[sample_index, channel]>0, cmap='gray')  # Display the first channel of the output\n",
        "    plt.title(\"Model Output Mask\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkTdAZTZYi39"
      },
      "source": [
        "The `train_model` function implements a simple training loop that iterates over a specified number of epochs. In each iteration, the model is trained on the training set and then evaluated on the validation set using the Dice score as the performance metric. The function returns the model as it is at the final epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-03T12:55:58.455847Z",
          "iopub.status.busy": "2024-10-03T12:55:58.455167Z"
        },
        "id": "TlOg4FmFPI4T",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "model = model.to(device)  # Move model to GPU if available\n",
        "\n",
        "# Training function with visualization support\n",
        "def train_model(\n",
        "    model: nn.Module,\n",
        "    dataloaders: dict[str, DataLoader],\n",
        "    criterion: nn.Module,\n",
        "    optimizer: optim.Optimizer,\n",
        "    num_epochs: int = 25\n",
        ") -> nn.Module:\n",
        "    \"\"\"\n",
        "    Trains the model over a specified number of epochs using the given data loaders,\n",
        "    criterion (loss function), and optimizer.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The PyTorch model to be trained.\n",
        "        dataloaders (dict[str, DataLoader]): A dictionary containing 'train' and 'test' data loaders.\n",
        "        criterion (nn.Module): The loss function to be used for training.\n",
        "        optimizer (torch.optim.Optimizer): The optimizer used to adjust model parameters.\n",
        "        num_epochs (int, optional): Number of epochs for training. Defaults to 25.\n",
        "\n",
        "    Returns:\n",
        "        nn.Module: The trained model.\n",
        "    \"\"\"\n",
        "    since = time.time()\n",
        "\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    dice_scores_epoch = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        dice_scores = []\n",
        "        print(f'Epoch {epoch}/{num_epochs-1}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'test']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "\n",
        "            # Iterate over data\n",
        "            for inputs, masks in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                masks = masks.to(device)\n",
        "\n",
        "                # Zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "\n",
        "                    loss = criterion(outputs,masks)\n",
        "\n",
        "                    # Backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                    else:\n",
        "                        dice_scores.append(dice_score(outputs, masks))\n",
        "\n",
        "                # Statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            if phase == 'train':\n",
        "                train_losses.append(epoch_loss)\n",
        "            else:\n",
        "                test_losses.append(epoch_loss)\n",
        "                dice_scores_epoch.append(torch.tensor(dice_scores).mean().item())\n",
        "\n",
        "                visualize_mask(inputs, masks, outputs)\n",
        "\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f}')\n",
        "            if phase == 'test':\n",
        "                print(f'Dice score: {torch.tensor(dice_scores).mean()}')\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "\n",
        "    # Plot the results\n",
        "    epochs_range = range(num_epochs)\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs_range, train_losses, label=\"Train Loss\")\n",
        "    plt.plot(epochs_range, test_losses, label=\"Test Loss\")\n",
        "    plt.legend(loc=\"upper right\")\n",
        "    plt.title(\"Training and Test Loss\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs_range, dice_scores_epoch, label=\"Dice Score\", color=\"green\")\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.title(\"Dice Score\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    return model\n",
        "\n",
        "# Train the model\n",
        "model = train_model(model, dataloaders, criterion, optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOgSabiqrxe4"
      },
      "outputs": [],
      "source": [
        "model_save_path = \"model.pth\"\n",
        "torch.save(model.state_dict(), model_save_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30775,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "unet_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
